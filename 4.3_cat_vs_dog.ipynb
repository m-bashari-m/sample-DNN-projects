{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.3cat-vs-dog.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCMq4eFOfp6elAs4eTe7Md",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-bashari-m/sample-DNN-projects/blob/main/4.3_cat_vs_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2NVwHx1spvCF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir =  \"/root/.keras/datasets/cats_and_dogs_filtered/train\"\n",
        "validation_dir = \"/root/.keras/datasets/cats_and_dogs_filtered/validation\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.list_files(str(train_dir+'/*/*'))\n",
        "val_ds = tf.data.Dataset.list_files(str(validation_dir+'/*/*'))"
      ],
      "metadata": {
        "id": "eiEMHlrBpv2m"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in train_ds.take(5):\n",
        "  print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlC8mxlQumcA",
        "outputId": "21881167-95ce-41b5-836e-0e9dfe01fbff"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/dogs/dog.250.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/cats/cat.576.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/dogs/dog.449.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/dogs/dog.906.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/root/.keras/datasets/cats_and_dogs_filtered/train/cats/cat.653.jpg', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_labeled_data(path):\n",
        "  class_names = tf.constant(['cat', 'dog'])\n",
        "\n",
        "  categorical_label = tf.strings.split(path, '/')[-1]\n",
        "  categorical_label = tf.strings.split(categorical_label, '.')[0]\n",
        "  numerical_label = tf.cast(categorical_label == class_names[0], tf.int8) # cat=1, dog=0\n",
        "\n",
        "  image = tf.image.decode_image( tf.io.read_file(path), expand_animations=False )\n",
        "  \n",
        "  return image,  numerical_label"
      ],
      "metadata": {
        "id": "l-rKLkrmquoR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation(img):\n",
        "  img = tf.image.resize_with_crop_or_pad(img, 260, 260)\n",
        "  img = tf.image.random_crop(img, size=[256, 256, 3])\n",
        "  img = tf.image.random_brightness(img, max_delta=.2)\n",
        "  img = tf.image.random_flip_left_right(img)\n",
        "  return img"
      ],
      "metadata": {
        "id": "JSWTmQxX1pyj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(img):\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  return img / 255"
      ],
      "metadata": {
        "id": "H5sCM1rJ750M"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_preprocessing(path):\n",
        "  img, label = prepare_labeled_data(path)\n",
        "  img = augmentation(img)\n",
        "  img = normalization(img)\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "YlMUNFGZzLQ-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_preprocessing(path):\n",
        "  img, label = prepare_labeled_data(path)\n",
        "  img = normalization(img)\n",
        "  img = tf.image.resize(img, [256, 256])\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "N9AAX4IQq0CN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BUFFER_SIZE=1000"
      ],
      "metadata": {
        "id": "UNPqm5fs9Df4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(train_preprocessing).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(test_preprocessing).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "SJncam6bArD1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, lbl in train_ds.take(3):\n",
        "  print(img.shape)"
      ],
      "metadata": {
        "id": "9VYX2khMCNF6",
        "outputId": "abd8d02d-a0a3-4718-80aa-e195872dee9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 256, 256, 3)\n",
            "(64, 256, 256, 3)\n",
            "(64, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NormalizationAndActivation(tf.keras.layers.Layer):\n",
        "  def __init__(self, activation='relu', **kwargs):\n",
        "    super(NormalizationAndActivation, self).__init__(**kwargs)\n",
        "    self.activation = tf.keras.activations.get(activation)\n",
        "    self.batch_norm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, X):\n",
        "    return self.batch_norm(self.activation(X))\n"
      ],
      "metadata": {
        "id": "TvPuC2NasJHF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequentialBlock(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters, has_dropout=False, dropout_rate=.2, **kwargs):\n",
        "    super(SequentialBlock, self).__init__(**kwargs)\n",
        "    self.conv_1 = tf.keras.layers.Conv2D(filters, (3,3), padding='same')\n",
        "    self.bn_activation_1 = NormalizationAndActivation()\n",
        "    self.conv_2 = tf.keras.layers.Conv2D(filters, (3,3), strides=(2,2), padding='same')\n",
        "    self.bn_activation_2 = NormalizationAndActivation()\n",
        "    self.max_pool = tf.keras.layers.MaxPooling2D(2)\n",
        "\n",
        "    self.has_dropout = has_dropout\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, X):\n",
        "    X = self.conv_1(X)\n",
        "    X = self.bn_activation_1(X)\n",
        "    X = self.conv_2(X)\n",
        "    X = self.bn_activation_2(X)\n",
        "    X = self.max_pool(X)\n",
        "\n",
        "    if self.has_dropout:\n",
        "      X = self.dropout(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "QsezZa4_d_yj"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CatVsDog(tf.keras.models.Model):\n",
        "  def __init__(self, activation='relu', **kwargs):\n",
        "    super(CatVsDog, self).__init__(**kwargs)\n",
        "\n",
        "    self.blocks = [\n",
        "                   SequentialBlock(64),\n",
        "                   SequentialBlock(128),\n",
        "                   SequentialBlock(512, has_dropout=True),\n",
        "                   SequentialBlock(1024, has_dropout=True)]\n",
        "\n",
        "    self.model_layers = [\n",
        "                   tf.keras.layers.GlobalAveragePooling2D(name='avg_pool_1_26'),\n",
        "                   tf.keras.layers.Flatten(),\n",
        "                   tf.keras.layers.Dense(200, name='dense_1_27'),\n",
        "                   tf.keras.layers.Dropout(.5),\n",
        "                   tf.keras.layers.Dense(1, name='classifier'),\n",
        "                   tf.keras.layers.Activation('sigmoid')]\n",
        "\n",
        "  def call(self, X):\n",
        "    for block in self.blocks:\n",
        "      X = block(X)\n",
        "\n",
        "    for layer in self.model_layers:\n",
        "      X = layer(X)\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "vCprnTYIY7da"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = '/content/checkpoints'\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "except OSError as error:\n",
        "    pass\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(path, save_wights_only=True)\n"
      ],
      "metadata": {
        "id": "S8RNWqghx0q9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatVsDog()\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Nadam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WfDG_qkFvlM_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, \n",
        "                    epochs=25,\n",
        "                    batch_size=64,\n",
        "                    validation_data=val_ds)"
      ],
      "metadata": {
        "id": "5aPqNMH3wr4z",
        "outputId": "ba1546a0-cc5c-4f7d-a3b9-55244a6c0ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 96s 948ms/step - loss: 3.0748 - accuracy: 0.5360 - val_loss: 0.8734 - val_accuracy: 0.5000\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 33s 934ms/step - loss: 1.7984 - accuracy: 0.5595 - val_loss: 1.0838 - val_accuracy: 0.5000\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 34s 939ms/step - loss: 1.6273 - accuracy: 0.5300 - val_loss: 0.7632 - val_accuracy: 0.5000\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 33s 936ms/step - loss: 1.3087 - accuracy: 0.5705 - val_loss: 0.7068 - val_accuracy: 0.5000\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 34s 938ms/step - loss: 1.3106 - accuracy: 0.5580 - val_loss: 0.9731 - val_accuracy: 0.5000\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 33s 936ms/step - loss: 1.3275 - accuracy: 0.5845 - val_loss: 1.7628 - val_accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 34s 937ms/step - loss: 1.0776 - accuracy: 0.6095 - val_loss: 1.0117 - val_accuracy: 0.5000\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 33s 932ms/step - loss: 1.0847 - accuracy: 0.5990 - val_loss: 1.4796 - val_accuracy: 0.5000\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 33s 937ms/step - loss: 1.0285 - accuracy: 0.6055 - val_loss: 1.8877 - val_accuracy: 0.5000\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 33s 930ms/step - loss: 0.9920 - accuracy: 0.5920 - val_loss: 2.2346 - val_accuracy: 0.5000\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 33s 939ms/step - loss: 0.8914 - accuracy: 0.6110 - val_loss: 0.7273 - val_accuracy: 0.5000\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 33s 934ms/step - loss: 0.8359 - accuracy: 0.6590 - val_loss: 1.9901 - val_accuracy: 0.5000\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 33s 936ms/step - loss: 0.8311 - accuracy: 0.6455 - val_loss: 0.8085 - val_accuracy: 0.5040\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 33s 932ms/step - loss: 0.7651 - accuracy: 0.6470 - val_loss: 1.0794 - val_accuracy: 0.5000\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 33s 935ms/step - loss: 0.6959 - accuracy: 0.6770 - val_loss: 0.7406 - val_accuracy: 0.4980\n",
            "Epoch 16/25\n",
            "32/32 [==============================] - 33s 931ms/step - loss: 0.7073 - accuracy: 0.6760 - val_loss: 0.7411 - val_accuracy: 0.4990\n",
            "Epoch 17/25\n",
            "32/32 [==============================] - 33s 935ms/step - loss: 0.7158 - accuracy: 0.6875 - val_loss: 0.9027 - val_accuracy: 0.5010\n",
            "Epoch 18/25\n",
            "32/32 [==============================] - 33s 933ms/step - loss: 0.6210 - accuracy: 0.7150 - val_loss: 1.1728 - val_accuracy: 0.5140\n",
            "Epoch 19/25\n",
            "32/32 [==============================] - 33s 935ms/step - loss: 0.6023 - accuracy: 0.7325 - val_loss: 0.6848 - val_accuracy: 0.5650\n",
            "Epoch 20/25\n",
            "32/32 [==============================] - 33s 935ms/step - loss: 0.5606 - accuracy: 0.7410 - val_loss: 1.5563 - val_accuracy: 0.5330\n",
            "Epoch 21/25\n",
            "32/32 [==============================] - 33s 935ms/step - loss: 0.5849 - accuracy: 0.7495 - val_loss: 0.6612 - val_accuracy: 0.6490\n",
            "Epoch 22/25\n",
            "32/32 [==============================] - 33s 934ms/step - loss: 0.5064 - accuracy: 0.7625 - val_loss: 0.6118 - val_accuracy: 0.6600\n",
            "Epoch 23/25\n",
            "32/32 [==============================] - 34s 938ms/step - loss: 0.5002 - accuracy: 0.7875 - val_loss: 0.6165 - val_accuracy: 0.6610\n",
            "Epoch 24/25\n",
            "32/32 [==============================] - 33s 936ms/step - loss: 0.4627 - accuracy: 0.8000 - val_loss: 0.6693 - val_accuracy: 0.5950\n",
            "Epoch 25/25\n",
            "32/32 [==============================] - 33s 935ms/step - loss: 0.4373 - accuracy: 0.7960 - val_loss: 0.7828 - val_accuracy: 0.5590\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f801df68c90>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}